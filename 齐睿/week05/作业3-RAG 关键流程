## 概述

本文档描述了一个基于检索增强生成（Retrieval-Augmented Generation, RAG）的系统流程，该系统用于处理用户查询，通过检索相关文档片段并结合大语言模型生成回答。
## 主要组件

### 1. 配置加载
- 使用 `config.yaml` 文件存储系统配置
- 配置内容包括：
  - 设备设置（CPU/GPU）
  - RAG 相关参数（是否使用嵌入/重排序模型、分块大小等）
  - 模型路径信息
  - API 密钥和基础URL
### 2. 模型加载
#### 嵌入模型
- 支持模型：`bge-small-zh-v1.5`, `bge-base-zh-v1.5`
- 使用 `SentenceTransformer` 进行文本编码
- 特征归一化：`normalize_embeddings=True`
#### 重排序模型
- 支持模型：`bge-reranker-base`
- 使用 `AutoModelForSequenceClassification` 和 `AutoTokenizer`
- 模型运行在指定设备上（CPU/GPU）
### 3. 文本处理
#### 文本分块
- 函数：`split_text_with_overlap`
- 参数：
  - `chunk_size`: 分块大小
  - `chunk_overlap`: 重叠大小
- 实现有重叠的文本分块，确保上下文连续性
### 4. RAG 类核心功能
#### 文档内容提取
- **PDF 处理** (`_extract_pdf_content`)
  - 使用 `pdfplumber` 提取文本内容
  - 处理流程：
    1. 提取前3页作为摘要
    2. 存储整页文本到 Elasticsearch
    3. 对每页内容进行分块处理
    4. 为每个文本块生成嵌入向量
  - 存储结构：
    - 块信息索引：`chunk_info`
    - 文档元数据索引：`document_meta`
#### 嵌入向量生成
- 方法：`get_embedding`
- 使用配置的嵌入模型对文本进行编码
- 返回归一化后的嵌入向量
#### 重排序功能
- 方法：`get_rank`
- 对查询-文档对进行相关性评分
- 使用交叉编码器计算匹配分数
#### 文档检索
- 方法：`query_document`
- 采用多策略检索：
  1. **全文检索**：基于 BM25 算法
  2. **语义检索**：基于向量相似度（kNN 搜索）
  3. **结果融合**：使用 Reciprocal Rank Fusion (RRF) 算法
- 可选重排序步骤提升结果质量
#### 对话生成
- 方法：`chat_with_rag`
- 流程：
  1. 检索相关文档片段
  2. 构建提示模板（`BASIC_QA_TEMPLATE`）
  3. 调用大语言模型生成回答
  4. 处理多轮对话上下文
## 核心流程

### 1. 文档入库流程
```
文件上传 → 内容提取 → 文本分块 → 向量化 → 存储到ES
```
### 2. 查询处理流程
```
用户查询 → 向量化 → 多路检索 → 结果融合 → 重排序 → 提示构建 → LLM生成 → 返回结果
```

### 3. 检索策略细节
- **RRF 参数**：k=60
- **候选数量**：初步检索50/100个候选，最终选择`chunk_candidate`个
- **过滤条件**：按`knowledge_id`过滤，确保在同一知识库内检索

## 关键配置参数

| 参数              | 描述       | 示例值  |
| --------------- | -------- | ---- |
| chunk_size      | 文本分块大小   | 512  |
| chunk_overlap   | 分块重叠大小   | 50   |
| chunk_candidate | 最终候选数量   | 10   |
| use_embedding   | 是否使用嵌入模型 | true |
| use_rerank      | 是否使用重排序  | true |

## 提示模板

```python
BASIC_QA_TEMPLATE = '''现在的时间是{#TIME#}。你是一个专家，你擅长回答用户提问，帮我结合给定的资料，回答下面的问题。
如果问题无法从资料中获得，或无法从资料中进行回答，请回答无法回答。如果提问不符合逻辑，请回答无法回答。
如果问题可以从资料中获得，则请逐步回答。

资料：
{#RELATED_DOCUMENT#}

问题：{#QUESTION#}
```

## 异常处理

- 文件打开失败处理
- 模型未实现异常
- 检索过程中的错误处理

## 依赖项

- `yaml`: 配置解析
- `numpy`: 数值计算
- `pdfplumber`: PDF 处理
- `openai`: LLM API 调用
- `torch`: 深度学习框架
- `transformers`: 预训练模型
- `sentence-transformers`: 句子嵌入
- `elasticsearch`: 检索服务

## 扩展性

- 支持多种嵌入模型
- 支持多种重排序模型
- 可扩展的文件类型处理（目前支持PDF）
- 模块化设计，易于添加新功能
