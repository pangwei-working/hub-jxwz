
[TOC]

### Project Organization
bert_tune_proj/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # FastAPI ä¸»æ–‡ä»¶
â”‚   â”œâ”€â”€ bert_model.py    # è®­ç»ƒä»£ç 
â”‚   â”œâ”€â”€ predictor.py     # é¢„æµ‹æœåŠ¡ç±»
â”‚   â”œâ”€â”€ schemas.py       # Pydanticæ¨¡å‹
â”‚   â””â”€â”€ models/          # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
â”œâ”€â”€ assets
â”‚   â”œâ”€â”€models/           #google-bert-chinese model
â”‚   â”œâ”€â”€waimai_10k.csv     #æ•°æ®é›†
â”‚   â”œâ”€â”€post_data_multi.json  #ABæµ‹è¯•ç”¨å†…å®¹
â”‚   â””â”€â”€post_data.json        #ABæµ‹è¯•ç”¨å†…å®¹
â”œâ”€â”€ README.md             #ä½¿ç”¨è¯´æ˜ï¼Œå­˜åœ¨çš„é—®é¢˜ç­‰
â””â”€â”€ train.py            # è®­ç»ƒå…¥å£è„šæœ¬ 

### start train

cd ~/work/bert_tune_proj
python train.py
......
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./assets/models/google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using device: cpu
------------Epoch: 0 ----------------
Epoch: 0, Average training loss: 1.5514
Accuracy: 0.7768
Average testing loss: 0.8642
-------------------------------
Model saved to ./app/models/bert-finetuned-epoch0
ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹ä¿å­˜ï¼Œå‡†ç¡®ç‡: 0.7768
------------Epoch: 1 ----------------
Epoch: 1, Average training loss: 0.5954
Accuracy: 0.8929
Average testing loss: 0.3957
-------------------------------
Model saved to ./app/models/bert-finetuned-epoch1
ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹ä¿å­˜ï¼Œå‡†ç¡®ç‡: 0.8929
------------Epoch: 2 ----------------
Epoch: 2, Average training loss: 0.2657
Accuracy: 0.8929
Average testing loss: 0.4232
-------------------------------
------------Epoch: 3 ----------------
Epoch: 3, Average training loss: 0.1442
Accuracy: 0.8750
Average testing loss: 0.6480
-------------------------------

è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: 0.8929

### run service
cd ~/work/bert_tune_proj
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 &
[1] 21599
(pytorch_d2l) 192:bert_tune_proj wenyuc$ INFO:     Will watch for changes in these directories: ['/Users/wenyuc/work/bert_tune_proj']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [21599] using StatReload
INFO:     Started server process [21602]
INFO:     Waiting for application startup.
å°è¯•åŠ è½½æ¨¡å‹ä»: app/models/bert-finetuned-epoch0
è·¯å¾„æ˜¯å¦å­˜åœ¨: True
INFO:app.predictor:Using device: cpu
INFO:app.predictor:æ¨¡å‹ç›®å½•æ–‡ä»¶: ['model.safetensors', 'label_encoder.pkl', 'tokenizer_config.json', 'special_tokens_map.json', 'config.json', 'vocab.txt']
INFO:app.predictor:å¼€å§‹åŠ è½½æ¨¡å‹...
INFO:app.predictor:æ¨¡å‹åŠ è½½æˆåŠŸ
INFO:app.predictor:å¼€å§‹åŠ è½½åˆ†è¯å™¨...
INFO:app.predictor:åˆ†è¯å™¨åŠ è½½æˆåŠŸ
INFO:app.predictor:æ ‡ç­¾ç¼–ç å™¨åŠ è½½æˆåŠŸï¼Œç±»åˆ«: [0, 1]
âœ… Model loaded successfully
Predictor type: <class 'app.predictor.BertPredictor'>
Predictor device: cpu
INFO:     Application startup complete.
#### Tips 
æŸ¥æ‰¾å ç”¨8000ç«¯å£çš„è¿›ç¨‹
lsof -i :8000
æˆ–è€…ä½¿ç”¨
netstat -anv | grep 8000
### Stop Service
pkill -f uvicorn

### test api
#### 1. å¥åº·æ£€æŸ¥
curl http://localhost:8000/health
Health check - predictor: <app.predictor.BertPredictor object at 0x12c06b220>
INFO:     127.0.0.1:56039 - "GET /health HTTP/1.1" 200 OK
{"status":"healthy","model_loaded":true,"device":"cpu"}

#### 2. Debug predict return value
curl http://localhost:8000/debug-predict
INFO:     127.0.0.1:56101 - "GET /debug-predict HTTP/1.1" 200 OK
{"type":"<class 'list'>","value":"[{'text': 'è¿™', 'predicted_label': 1, 'predicted_class': 1, 'confidence': 0.900057315826416}]","is_numpy":false,"converted":[{"text":"è¿™","predicted_label":1,"predicted_class":1,"confidence":0.900057315826416}],"converted_type":"<class 'list'>"}

#### 2. å•ä¸ªé¢„æµ‹
curl -X POST "http://localhost:8000/predict/è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨"
INFO:     127.0.0.1:56169 - "POST /predict/%E8%BF%99%E4%B8%AA%E4%BA%A7%E5%93%81%E5%BE%88%E5%A5%BD%E7%94%A8 HTTP/1.1" 200 OK
{"text":"è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨","predicted_label":"1","predicted_class":1,"confidence":0.9001}

#### 3. æ‰¹é‡é¢„æµ‹(è¿˜åœ¨è°ƒè¯•é˜¶æ®µ)
curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"texts": ["è¿™ä¸ªå¾ˆå¥½", "é‚£ä¸ªä¸å¥½"]}'

INFO:     127.0.0.1:58910 - "POST /predict HTTP/1.1" 200 OK
INFO:     127.0.0.1:51000 - "POST /predict HTTP/1.1" 200 OK
[{"text":"è¿™ä¸ªå¾ˆå¥½","predicted_label":"1","predicted_class":1,"confidence":0.7766},{"text":"é‚£ä¸ªä¸å¥½","predicted_label":"0","predicted_class":0,"confidence":0.7985}]

### ABæµ‹è¯•ç»“æœ

ab -n 100 -c 1 -p ./assets/post_data_multi.json -T "application/json" http://127.0.0.1:8000/predict
This is ApacheBench, Version 2.3 <$Revision: 1913912 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)...predict batch: ['è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨', 'å¥½åƒå¾—æ²¡è¯è¯´', 'è¿™ä¸ªäº§å“ç®€ç›´æ²¡æ³•ç”¨', 'è¿˜æ˜¯ç­‰ä¸‹ä¸€ä¸ªæ–°äº§å“å§', 'ä¸å¤ªå¥½åƒ']
..done

Server Software:        uvicorn
Server Hostname:        127.0.0.1
Server Port:            8000

Document Path:          /predict
Document Length:        478 bytes

Concurrency Level:      1
Time taken for tests:   6.173 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      62300 bytes
Total body sent:        29000
HTML transferred:       47800 bytes
Requests per second:    16.20 [#/sec] (mean)
Time per request:       61.726 [ms] (mean)
Time per request:       61.726 [ms] (mean, across all concurrent requests)
Transfer rate:          9.86 [Kbytes/sec] received
                        4.59 kb/s sent
                        14.44 kb/s total

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    57   62   6.2     60     109
Waiting:       57   61   6.2     60     109
Total:         58   62   6.2     60     109

Percentage of the requests served within a certain time (ms)
  50%     60
  66%     61
  75%     62
  80%     62
  90%     64
  95%     73
  98%     82
  99%    109
 100%    109 (longest request)

$ab -n 100 -c 5 -p ./assets/post_data_multi.json -T "application/json" http://127.0.0.1:8000/predict
This is ApacheBench, Version 2.3 <$Revision: 1913912 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)...INFO:     127.0.0.1:52141 - "POST /predict HTTP/1.0" 200 OK
..done

Server Software:        uvicorn
Server Hostname:        127.0.0.1
Server Port:            8000

Document Path:          /predict
Document Length:        478 bytes

Concurrency Level:      5
Time taken for tests:   6.702 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      62300 bytes
Total body sent:        29000
HTML transferred:       47800 bytes
Requests per second:    14.92 [#/sec] (mean)
Time per request:       335.118 [ms] (mean)
Time per request:       67.024 [ms] (mean, across all concurrent requests)
Transfer rate:          9.08 [Kbytes/sec] received
                        4.23 kb/s sent
                        13.30 kb/s total

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       0
Processing:    85  325  61.7    320     463
Waiting:       61  235  88.3    252     434
Total:         85  326  61.7    320     463

Percentage of the requests served within a certain time (ms)
  50%    320
  66%    336
  75%    345
  80%    348
  90%    412
  95%    434
  98%    463
  99%    463
 100%    463 (longest request)

(pytorch_d2l) 192:bert_tune_proj wenyuc$ ab -n 100 -c 10 -p ./assets/post_data.json -T "application/json" http://127.0.0.1:8000/predict
This is ApacheBench, Version 2.3 <$Revision: 1913912 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking 127.0.0.1 (be patient)...INFO:     127.0.0.1:52306 - "POST /predict HTTP/1.0" 200 OK
......
..done


Server Software:        uvicorn
Server Hostname:        127.0.0.1
Server Port:            8000

Document Path:          /predict
Document Length:        478 bytes

Concurrency Level:      10
Time taken for tests:   6.481 seconds
Complete requests:      100
Failed requests:        0
Total transferred:      62300 bytes
Total body sent:        29000
HTML transferred:       47800 bytes
Requests per second:    15.43 [#/sec] (mean)
Time per request:       648.147 [ms] (mean)
Time per request:       64.815 [ms] (mean, across all concurrent requests)
Transfer rate:          9.39 [Kbytes/sec] received
                        4.37 kb/s sent
                        13.76 kb/s total

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       0
Processing:    86  634  95.2    623     808
Waiting:       61  360 186.9    369     778
Total:         86  635  95.2    624     808

Percentage of the requests served within a certain time (ms)
  50%    624
  66%    628
  75%    643
  80%    682
  90%    779
  95%    808
  98%    808
  99%    808
 100%    808 (longest request)

### å­˜åœ¨çš„é—®é¢˜
1. æ¨¡å‹å¢å¤§è®­ç»ƒæ ·æœ¬ï¼Œä¿å­˜æœ€é«˜ç²¾åº¦çš„æ¨¡å‹è¿˜è¦è°ƒæ•´
2. APIæ¥å£ç»§ç»­å®Œå–„
